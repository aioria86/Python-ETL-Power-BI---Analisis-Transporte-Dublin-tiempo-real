# üöå Sistema de Inteligencia de Transporte - Irlanda (NTA)

Este proyecto es un ecosistema de datos de alto rendimiento que integra telemetr√≠a en tiempo real (GTFS-R) con la estructura oficial de horarios y rutas (GTFS Static) de la National Transport Authority de Irlanda. El pipeline automatiza la captura, el enriquecimiento clim√°tico y el almacenamiento en un Data Lake local para an√°lisis avanzado en Power BI.

## üöÄ Caracter√≠sticas y Capacidades
- **Streaming H√≠brido:** Captura de datos cada 20 segundos y env√≠o a Power BI Service para monitoreo "Live".
- **Integraci√≥n GTFS Pro:** Uso de archivos maestros (`agency`, `routes`, `trips`, `stops`) para normalizar la telemetr√≠a.
- **Data Lake con Hive Partitioning:** Almacenamiento en archivos **Parquet** particionados por fecha para optimizar lecturas masivas.
- **Correlaci√≥n Meteorol√≥gica:** Integraci√≥n con Open-Meteo API para cruzar retrasos de flota con intensidad de lluvia (mm/h).
- **Modelo Relacional 2.0:** Esquema en estrella puro con relaciones unidireccionales de integridad referencial.

## üõ†Ô∏è Requisitos e Infraestructura

1. **Datos Maestros (GTFS Static):**
   - Descarga los archivos `.txt` oficiales de la [NTA Developer Portal](https://developer.nationaltransport.ie/api-details#api=gtfsr&operation=gtfsr-v2).
   - Estos archivos (`routes`, `agency`, `trips`, `calendar`, `stops`) son la base de las Dimensiones del modelo.

2. **API Key de la NTA:**
   - Suscr√≠bete a la API **GTFS Realtime v2** para obtener tu `Primary Key`.

3. **Power BI Desktop & Service:**
   - Modelo configurado para manejar conjuntos de datos de streaming y almacenamiento local hist√≥rico.

## üìä Arquitectura del Modelo de Datos (Esquema en Estrella)

El modelo en Power BI ha sido optimizado para eliminar redundancias y permitir an√°lisis de causa-efecto:

### Tablas de Hechos (Facts)
- **Fact_Monitoreo_Buses:** Telemetr√≠a GPS hist√≥rica y estado de puntualidad (delay_min).
- **Fact_Clima:** Hist√≥rico de precipitaciones y temperatura por hora y regi√≥n.

### Dimensiones Maestras (GTFS Based)
- **Dim_GTFS_Routes:** Nombres reales de rutas (ej. "L12: Ballywaltrim - Bray").
- **Dim_GTFS_Agency:** Operadores de transporte (Dublin Bus, Go-Ahead, Irish Rail).
- **Dim_GTFS_Trips:** Relaci√≥n de viajes programados vs. ejecutados.
- **Dim_GTFS_Stops:** Coordenadas de paradas oficiales para an√°lisis geogr√°fico.
- **Dim_Calendario_Universal:** Dimensi√≥n temporal √∫nica para sincronizaci√≥n de hechos.
- **Dim_Operativa_Dias (Calendar):** Reglas de servicio por service_id (L-D).



## üèóÔ∏è Estructura del Data Lake (Parquet)

El sistema utiliza una estructura de carpetas optimizada para Power BI (Hive Partitioning), permitiendo cargar a√±os de datos en segundos:

```text
data/
 ‚îî‚îÄ‚îÄ fecha=YYYY-MM-DD/
      ‚îî‚îÄ‚îÄ HH_MM_SS_buses.parquet
data_clima/
 ‚îî‚îÄ‚îÄ fecha=YYYY-MM-DD/
      ‚îî‚îÄ‚îÄ clima_regional.parquet
```

## ‚öôÔ∏è Configuraci√≥n del Proyecto

1. **Variables de Entorno:**
   Crea un archivo `.env` en la ra√≠z:
   ```env
   NTA_API_KEY=tu_clave_aqui
   POWERBI_URL=tu_url_de_insercion_aqui

2. **Ejecuci√≥n con Docker::**
   Construye y corre el contenedor vinculando el volumen para el hist√≥rico:

**Ejecuci√≥n con Docker: Construye la imagen:**
     docker build -t transporte-irlanda .

**Captura de buses (Tiempo real):**
     docker run --env-file .env -v "${PWD}/data:/app/data" transporte-irlanda python src/main.py

**Captura de clima (Hist√≥rico D-1):**
     docker run --rm -v "${PWD}:/app" transporte-irlanda python src/clima.py


## üìÇ Almacenamiento Hist√≥rico (Parquet)

El script crea autom√°ticamente una estructura de carpetas tipo Data Lake para facilitar la lectura masiva: data/fecha=YYYY-MM-DD/HH_MM_SS.parquet

**Buses:** data/fecha=YYYY-MM-DD/HH_MM_SS.parquet

**Clima:** data_clima/fecha=YYYY-MM-DD/clima.parquet

Esta estructura permite a Power BI Desktop cargar la carpeta completa y reconocer autom√°ticamente la columna de fecha por el nombre de la subcarpeta (Hive Partitioning).




## Nota Operativa:

Los datos de buses se recolectan preferentemente en la ventana cr√≠tica de 10:00 a 18:00 para optimizar el almacenamiento del Data Lake.
